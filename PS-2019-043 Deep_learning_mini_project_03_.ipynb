{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "English to Sinhala Translation"
      ],
      "metadata": {
        "id": "v_CpvDJdYZTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Library Imports"
      ],
      "metadata": {
        "id": "WnH4HK-gYl31"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5qD0G41DYBnT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparation of data"
      ],
      "metadata": {
        "id": "2M82Xp0GYYTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting the google drive"
      ],
      "metadata": {
        "id": "24HBLPQSZDjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMAQkuTdZPwg",
        "outputId": "1736fe61-d7f4-47fa-b3e0-625351a86ef9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the data file"
      ],
      "metadata": {
        "id": "ZVjtxiWjZkB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = \"/content/drive/My Drive/Deep Learning/EnglishToSinhalaDataset.txt\"\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "i = 0\n",
        "for line in lines:\n",
        "  print(line)\n",
        "  i = i + 1\n",
        "  if(i==20):\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2arIVy4ZZnRw",
        "outputId": "5c280551-2589-4846-b606-889bc444d598"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tයන්න.\n",
            "Hi.\tආයුබෝවන්.\n",
            "Run.\tදුවන්න.\n",
            "Who?\tකව්ද?\n",
            "Wow!\tවාව්!\n",
            "Fire.\tගින්නක්.\n",
            "Help.\tඋදව්.\n",
            "Hide.\tසඟවන්න.\n",
            "Jump.\tපනින්න.\n",
            "Stay.\tරැඳී සිටින්න.\n",
            "Stop.\tනවත්වන්න.\n",
            "Wait.\tඉන්න.\n",
            "Begin.\tආරම්භය.\n",
            "Go on.\tදිගටම යන්න.\n",
            "Hello!\tහෙලෝ!\n",
            "Hurry!\tඉක්මන් කරන්න!\n",
            "I hid.\tමම සැඟවී සිටියෙමි.\n",
            "I ran.\tමම දිව්වා.\n",
            "I try.\tමම උත්සාහ කරමි.\n",
            "I won.\tමම දිනුවා.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(len(lines)-10,len(lines)):\n",
        "  print(lines[x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AH3nW3has1F",
        "outputId": "b3583482-9818-4790-f30a-410feb1c81c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No matter how much you try to convince people that chocolate is vanilla, it'll still be chocolate, even though you may manage to convince yourself and a few others that it's vanilla.\tචොක්ලට් යනු වැනිලා බව මිනිසුන්ට ඒත්තු ගැන්වීමට ඔබ කොතරම් උත්සාහ කළත්, එය වැනිලා බව ඔබට සහ තවත් කිහිප දෙනෙකුට ඒත්තු ගැන්විය හැකි වුවද, එය තවමත් චොකලට් වනු ඇත.\n",
            "In 1969, Roger Miller recorded a song called \"You Don't Want My Love.\" Today, this song is better known as \"In the Summer Time.\" It's the first song he wrote and sang that became popular.\t1969 දී රොජර් මිලර් \"ඔබට මගේ ආදරය අවශ්‍ය නැත\" නමින් ගීතයක් පටිගත කළේය. අද මෙම ගීතය වඩාත් ප්‍රචලිත වන්නේ \"ගිම්හානයේ\" යනුවෙනි. එය ඔහු ලියූ සහ ගායනා කළ පළමු ගීතය ජනප්‍රිය විය.\n",
            "A child who is a native speaker usually knows many things about his or her language that a non-native speaker who has been studying for years still does not know and perhaps will never know.\tස්වදේශික කථිකයෙකු වන දරුවෙකු සාමාන්‍යයෙන් ඔහුගේ හෝ ඇයගේ භාෂාව පිළිබඳ බොහෝ දේ දන්නා අතර එය වසර ගණනාවක් තිස්සේ අධ්‍යයනය කරන ස්වදේශික නොවන කථිකයෙකු තවමත් නොදන්නා සහ කිසි විටෙකත් නොදැන සිටිය හැකිය.\n",
            "There are four main causes of alcohol-related death. Injury from car accidents or violence is one. Diseases like cirrhosis of the liver, cancer, heart and blood system diseases are the others.\tමත්පැන් නිසා සිදුවන මරණවලට ප්‍රධාන හේතු හතරක් තිබේ. රිය අනතුරකින් හෝ ප්‍රචණ්ඩත්වයකින් තුවාල වීම එකකි. අක්මාවේ සිරෝසිස්, පිළිකා, හෘද රෝග සහ රුධිර සංසරණ පද්ධතිය වැනි රෝග අනෙක් ඒවා වේ.\n",
            "There are mothers and fathers who will lie awake after the children fall asleep and wonder how they'll make the mortgage, or pay their doctor's bills, or save enough for their child's college education.\tඋකස් හෝ දොස්තරගේ බිල් ගෙවන්නේ කෙසේද, දරුවන්ගේ විශ්වවිද්‍යාල අධ්‍යාපනයට ප්‍රමාණවත් මුදලක් ඉතිරි කරන්නේ කෙසේදැයි කල්පනා කරමින් දරුවන් නිදාගත් පසු අවදියෙන් සිටින අම්මලා තාත්තලාද සිටිති.\n",
            "A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.\tකාබන් පියසටහනක් යනු අපගේ ක්‍රියාකාරකම්වල ප්‍රතිඵලයක් ලෙස අප විසින් නිපදවන කාබන්ඩයොක්සයිඩ් දූෂණ ප්‍රමාණයයි. සමහර අය දේශගුණික විපර්යාස ගැන සැලකිලිමත් වන නිසා ඔවුන්ගේ කාබන් පියසටහන අඩු කිරීමට උත්සාහ කරති.\n",
            "Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\tඕනෑම මාතෘකාවක සාමාන්‍යයෙන් වෙබ් පිටු කිහිපයක් ඇති බැවින්, මම සාමාන්‍යයෙන් උත්පතන දැන්වීම් ඇති වෙබ් පිටුවකට පැමිණෙන විට ආපසු බොත්තම ඔබන්නෙමි. මම සරලවම Google විසින් සොයා ගන්නා ලද ඊළඟ පිටුවට ගොස් අඩු කෝපයක් ඇති දෙයක් සොයා ගැනීමට බලාපොරොත්තු වෙමි.\n",
            "If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\tඔබට ස්වදේශික කථිකයෙකු ලෙස ශබ්ද කිරීමට අවශ්‍ය නම්, බැන්ජෝ වාදකයෙකු එම වාක්‍ය ඛණ්ඩය නිවැරදිව හා නියමිත වේලාවට වාදනය කරන තෙක් එකම වාක්‍ය ඛණ්ඩය නැවත නැවතත් කීමට පුහුණු වීමට ඔබ කැමති විය යුතුය.\n",
            "It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors.\tමෙම ආකාරයේ සහයෝගී ප්‍රයත්නයේ ස්වභාවය නිසා සම්පූර්ණ දෝෂ රහිත corpus එකක් ලබා ගැනීමට නොහැකි විය හැක. කෙසේ වෙතත්, ඔවුන් ඉගෙන ගන්නා භාෂා සමඟ අත්හදා බැලීම් කරනවාට වඩා ඔවුන්ගේම භාෂාවෙන් වාක්‍ය ඛණ්ඩ දායක කිරීමට අපි සාමාජිකයින් දිරිමත් කරන්නේ නම්, අපට දෝෂ අවම කර ගැනීමට හැකි වනු ඇත.\n",
            "One day, I woke up to find that God had put hair on my face. I shaved it off. The next day, I found that God had put it back on my face, so I shaved it off again. On the third day, when I found that God had put hair back on my face again, I decided to let God have his way. That's why I have a beard.\tදවසක් මම ඇහැරිලා බැලුවා දෙවියන් මගේ මූණට කෙස් ගහලා කියලා. මම ඒක රැවුල කැපුවා. ඊළඟ දවසේ, දෙවියන් වහන්සේ එය මගේ මුහුණට දමා ඇති බව මම දුටුවෙමි, මම එය නැවත රැවුල කපා ගත්තෙමි. තුන්වෙනි දවසේදී, දෙවියන් වහන්සේ නැවතත් මගේ මුහුණට හිසකෙස් දමා ඇති බව මම දුටු විට, මම දෙවියන් වහන්සේට ඔහුගේ මාර්ගයට ඉඩ දීමට තීරණය කළෙමි. ඒකයි මට රැවුල තියෙන්නේ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting the English and Sinhala translation pairs"
      ],
      "metadata": {
        "id": "edk7Rg87azLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pairs = []\n",
        "for line in lines:\n",
        "    english, sinhala = line.split(\"\\t\")\n",
        "    sinhala = \"[start] \" + sinhala + \" [end]\"\n",
        "    text_pairs.append((english, sinhala))\n",
        "for i in range(3):\n",
        "  print(random.choice(text_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjNo9Viia6u3",
        "outputId": "d8b2f4a0-9a9c-4361-8bea-afc6a0f31287"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Do you get along well with your new classmates?', '[start] ඔබ ඔබේ නව පන්තියේ මිතුරන් සමඟ හොඳින් ඇසුරු කරනවාද? [end]')\n",
            "('I think I lost my keys.', '[start] මම හිතන්නේ මගේ යතුරු නැති වුණා. [end]')\n",
            "('Chances are that I will be late for work.', '[start] ඔබ බොහෝ විට රැකියාවට ප්රමාද වනු ඇත. [end]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomize the data"
      ],
      "metadata": {
        "id": "hehv0IqBbDaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(text_pairs)"
      ],
      "metadata": {
        "id": "2S4-Xl92bFmy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data into training, validation and testing"
      ],
      "metadata": {
        "id": "XlxGH3yYbVkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]\n",
        "print(\"Total sentences:\",len(text_pairs))\n",
        "print(\"Training set size:\",len(train_pairs))\n",
        "print(\"Validation set size:\",len(val_pairs))\n",
        "print(\"Testing set size:\",len(test_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9p651FnbdTX",
        "outputId": "2b5ff0c8-e9d6-455c-f588-0aa84c319a63"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences: 125603\n",
            "Training set size: 87923\n",
            "Validation set size: 18840\n",
            "Testing set size: 18840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_pairs)+len(val_pairs)+len(test_pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fAQH9Ocbl0O",
        "outputId": "04ba4248-46de-4b06-9b04-9057f447c5f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125603"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Punctuation"
      ],
      "metadata": {
        "id": "5hlOFoXnbp5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")"
      ],
      "metadata": {
        "id": "xZq4_9dkbtL6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f\"[{re.escape(strip_chars)}]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Prva-kIIbyuq",
        "outputId": "fa79f5ee-263f-4d87-efbf-9518faa58cde"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\\\\\\\\\^_`\\\\{\\\\|\\\\}\\\\~¿]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f\"{3+5}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WYXLXLdab3lX",
        "outputId": "17f6c7d2-999f-42a9-96fc-af7b0108a956"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing the English and Sinhala Text Pairs"
      ],
      "metadata": {
        "id": "y0zDy5wub6FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_sinhala_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_sinhala_texts)"
      ],
      "metadata": {
        "id": "xZNTXQGXcAuP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing datasets for the translation task"
      ],
      "metadata": {
        "id": "_ZPXQWrtcK3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "def format_dataset(eng, spa):\n",
        "    eng = source_vectorization(eng)\n",
        "    spa = target_vectorization(spa)\n",
        "    return ({\n",
        "        \"english\": eng,\n",
        "        \"sinhala\": spa[:, :-1],\n",
        "    }, spa[:, 1:])\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)\n",
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
        "    print(f\"inputs['sinhala'].shape: {inputs['sinhala'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")\n",
        "inputs['english'].shape: (64, 20)\n",
        "inputs['sinhala'].shape: (64, 20)\n",
        "targets.shape: (64, 20)\n",
        "print(list(train_ds.as_numpy_iterator())[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa32NCepcUIj",
        "outputId": "9a4dfc97-cb59-4217-eef1-4678538291c6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['english'].shape: (64, 20)\n",
            "inputs['sinhala'].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n",
            "({'english': array([[   3,   36,   17, ...,    0,    0,    0],\n",
            "       [   2, 6699, 5999, ...,    0,    0,    0],\n",
            "       [  19,  165, 6041, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  91,   92,    6, ...,    0,    0,    0],\n",
            "       [   3, 2542,   13, ...,    0,    0,    0],\n",
            "       [   6,   43,    7, ...,    0,    0,    0]]), 'sinhala': array([[   2,    4,   30, ...,    0,    0,    0],\n",
            "       [   2, 8114, 6406, ...,    0,    0,    0],\n",
            "       [   2,    4, 1620, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2,   81,   18, ...,    0,    0,    0],\n",
            "       [   2,    4,   13, ...,    0,    0,    0],\n",
            "       [   2,   18, 1967, ...,    0,    0,    0]])}, array([[    4,    30, 10102, ...,     0,     0,     0],\n",
            "       [ 8114,  6406,  5866, ...,     0,     0,     0],\n",
            "       [    4,  1620,  3296, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [   81,    18,    88, ...,     0,     0,     0],\n",
            "       [    4,    13,  1667, ...,     0,     0,     0],\n",
            "       [   18,  1967,  5090, ...,     0,     0,     0]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer encoder implemented as a subclassed layer"
      ],
      "metadata": {
        "id": "A0Bm8ElUca9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "117wLaWuchvn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Transformer Decoder"
      ],
      "metadata": {
        "id": "OPKkcq6ecovA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = mask\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ],
      "metadata": {
        "id": "B2iPbkcUcrL3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional Encoding"
      ],
      "metadata": {
        "id": "BvHFfyDJc50y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "LYyQa3IQc8PR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "End To End Transformer"
      ],
      "metadata": {
        "id": "s3xwMK3LdA7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"sinhala\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqTBf0wSdGge",
        "outputId": "8676826f-9615-4cba-822e-db6d639c7573"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " sinhala (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding (Posi  (None, None, 256)            3845120   ['english[0][0]']             \n",
            " tionalEmbedding)                                                                                 \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Po  (None, None, 256)            3845120   ['sinhala[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Trans  (None, None, 256)            3155456   ['positional_embedding[0][0]']\n",
            " formerEncoder)                                                                                   \n",
            "                                                                                                  \n",
            " transformer_decoder (Trans  (None, None, 256)            5259520   ['positional_embedding_1[0][0]\n",
            " formerDecoder)                                                     ',                            \n",
            "                                                                     'transformer_encoder[0][0]'] \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, None, 256)            0         ['transformer_decoder[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, None, 15000)          3855000   ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19960216 (76.14 MB)\n",
            "Trainable params: 19960216 (76.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Sequence To Sequence Transformer"
      ],
      "metadata": {
        "id": "CpJdVcVKdLts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "transformer.fit(train_ds, epochs=50, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bROJv-_dTj8",
        "outputId": "0e235939-bff1-4ec0-876f-dc39a9e227b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1374/1374 [==============================] - 109s 73ms/step - loss: 4.3415 - accuracy: 0.4102 - val_loss: 3.4771 - val_accuracy: 0.4893\n",
            "Epoch 2/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 3.3915 - accuracy: 0.5031 - val_loss: 3.0651 - val_accuracy: 0.5386\n",
            "Epoch 3/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 3.0961 - accuracy: 0.5403 - val_loss: 2.9227 - val_accuracy: 0.5627\n",
            "Epoch 4/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 2.9375 - accuracy: 0.5634 - val_loss: 2.8578 - val_accuracy: 0.5736\n",
            "Epoch 5/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.8414 - accuracy: 0.5797 - val_loss: 2.8532 - val_accuracy: 0.5788\n",
            "Epoch 6/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.7746 - accuracy: 0.5915 - val_loss: 2.8466 - val_accuracy: 0.5816\n",
            "Epoch 7/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.7143 - accuracy: 0.6023 - val_loss: 2.8550 - val_accuracy: 0.5834\n",
            "Epoch 8/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.6625 - accuracy: 0.6113 - val_loss: 2.8345 - val_accuracy: 0.5897\n",
            "Epoch 9/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.6170 - accuracy: 0.6196 - val_loss: 2.8455 - val_accuracy: 0.5916\n",
            "Epoch 10/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.5714 - accuracy: 0.6272 - val_loss: 2.8408 - val_accuracy: 0.5913\n",
            "Epoch 11/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.5347 - accuracy: 0.6330 - val_loss: 2.8549 - val_accuracy: 0.5936\n",
            "Epoch 12/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 2.4982 - accuracy: 0.6398 - val_loss: 2.8587 - val_accuracy: 0.5950\n",
            "Epoch 13/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.4668 - accuracy: 0.6448 - val_loss: 2.8573 - val_accuracy: 0.5943\n",
            "Epoch 14/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.4382 - accuracy: 0.6495 - val_loss: 2.8827 - val_accuracy: 0.5953\n",
            "Epoch 15/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 2.4101 - accuracy: 0.6545 - val_loss: 2.8844 - val_accuracy: 0.5961\n",
            "Epoch 16/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 2.3843 - accuracy: 0.6589 - val_loss: 2.8727 - val_accuracy: 0.5983\n",
            "Epoch 17/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.3585 - accuracy: 0.6635 - val_loss: 2.8675 - val_accuracy: 0.6009\n",
            "Epoch 18/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.3361 - accuracy: 0.6667 - val_loss: 2.8897 - val_accuracy: 0.5982\n",
            "Epoch 19/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.3088 - accuracy: 0.6717 - val_loss: 2.9029 - val_accuracy: 0.6014\n",
            "Epoch 20/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.2880 - accuracy: 0.6753 - val_loss: 2.9052 - val_accuracy: 0.6014\n",
            "Epoch 21/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.2668 - accuracy: 0.6790 - val_loss: 2.8990 - val_accuracy: 0.6049\n",
            "Epoch 22/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.2428 - accuracy: 0.6824 - val_loss: 2.9103 - val_accuracy: 0.6052\n",
            "Epoch 23/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.2216 - accuracy: 0.6861 - val_loss: 2.9465 - val_accuracy: 0.6040\n",
            "Epoch 24/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.2002 - accuracy: 0.6900 - val_loss: 2.9372 - val_accuracy: 0.6027\n",
            "Epoch 25/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 2.1766 - accuracy: 0.6937 - val_loss: 2.9531 - val_accuracy: 0.6068\n",
            "Epoch 26/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.1572 - accuracy: 0.6971 - val_loss: 3.0044 - val_accuracy: 0.6062\n",
            "Epoch 27/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 2.1375 - accuracy: 0.6999 - val_loss: 3.0087 - val_accuracy: 0.6024\n",
            "Epoch 28/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.1156 - accuracy: 0.7034 - val_loss: 2.9803 - val_accuracy: 0.6060\n",
            "Epoch 29/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.0970 - accuracy: 0.7067 - val_loss: 3.0212 - val_accuracy: 0.6078\n",
            "Epoch 30/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.0756 - accuracy: 0.7103 - val_loss: 3.0666 - val_accuracy: 0.6028\n",
            "Epoch 31/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.0587 - accuracy: 0.7128 - val_loss: 3.0471 - val_accuracy: 0.6069\n",
            "Epoch 32/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.0404 - accuracy: 0.7159 - val_loss: 3.0368 - val_accuracy: 0.6086\n",
            "Epoch 33/50\n",
            "1374/1374 [==============================] - 95s 69ms/step - loss: 2.0225 - accuracy: 0.7183 - val_loss: 3.0558 - val_accuracy: 0.6073\n",
            "Epoch 34/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 2.0038 - accuracy: 0.7221 - val_loss: 3.0741 - val_accuracy: 0.6088\n",
            "Epoch 35/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.9911 - accuracy: 0.7241 - val_loss: 3.0885 - val_accuracy: 0.6121\n",
            "Epoch 36/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 1.9720 - accuracy: 0.7271 - val_loss: 3.1226 - val_accuracy: 0.6099\n",
            "Epoch 37/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.9535 - accuracy: 0.7299 - val_loss: 3.1149 - val_accuracy: 0.6089\n",
            "Epoch 38/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 1.9385 - accuracy: 0.7328 - val_loss: 3.1446 - val_accuracy: 0.6066\n",
            "Epoch 39/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.9207 - accuracy: 0.7355 - val_loss: 3.1618 - val_accuracy: 0.6111\n",
            "Epoch 40/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.9055 - accuracy: 0.7375 - val_loss: 3.1879 - val_accuracy: 0.6116\n",
            "Epoch 41/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.8898 - accuracy: 0.7401 - val_loss: 3.2154 - val_accuracy: 0.6057\n",
            "Epoch 42/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.8755 - accuracy: 0.7426 - val_loss: 3.2002 - val_accuracy: 0.6133\n",
            "Epoch 43/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.8580 - accuracy: 0.7452 - val_loss: 3.1900 - val_accuracy: 0.6130\n",
            "Epoch 44/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.8462 - accuracy: 0.7474 - val_loss: 3.2279 - val_accuracy: 0.6099\n",
            "Epoch 45/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.8325 - accuracy: 0.7496 - val_loss: 3.2721 - val_accuracy: 0.6115\n",
            "Epoch 46/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 1.8178 - accuracy: 0.7519 - val_loss: 3.2690 - val_accuracy: 0.6089\n",
            "Epoch 47/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.8052 - accuracy: 0.7543 - val_loss: 3.3199 - val_accuracy: 0.6096\n",
            "Epoch 48/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.7893 - accuracy: 0.7566 - val_loss: 3.2867 - val_accuracy: 0.6119\n",
            "Epoch 49/50\n",
            "1374/1374 [==============================] - 94s 69ms/step - loss: 1.7792 - accuracy: 0.7585 - val_loss: 3.3403 - val_accuracy: 0.6104\n",
            "Epoch 50/50\n",
            "1374/1374 [==============================] - 94s 68ms/step - loss: 1.7668 - accuracy: 0.7608 - val_loss: 3.3273 - val_accuracy: 0.6107\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fd761a1d5a0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "ELrYnfcq6Exd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = transformer(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M89Z3xpN6HBe",
        "outputId": "ab0d8062-8397-4f17-a93e-d22ee7ff0e8a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Whose lyrics are these?\n",
            "[start] මේ [UNK] කාගේද [end]\n",
            "-\n",
            "It was no big deal, really.\n",
            "[start] එය ඇත්තටම විශාල නැත [end]\n",
            "-\n",
            "Are you ready for the trip?\n",
            "[start] ඔබ සංචාරය සඳහා සූදානම් කරනවාද [end]\n",
            "-\n",
            "I hadn't recognized the importance of this document until you told me about it.\n",
            "[start] අනතුරට හේතුව මට අද උදෑසන මට [UNK] [end]\n",
            "-\n",
            "He fed his dog at the same time every day.\n",
            "[start] එයා හැමදාම සමහර වෙලාවට මේ දවස්වල මගේ බල්ලා එකම කළා [end]\n",
            "-\n",
            "Tom smiled approvingly.\n",
            "[start] ටොම් කෑ ගැහුවා [end]\n",
            "-\n",
            "You broke your leg.\n",
            "[start] ඔබේ කර ජලය [UNK] [end]\n",
            "-\n",
            "Do this work by tomorrow if at all possible.\n",
            "[start] මේ සියල්ල ක්‍රියා විරහිත [UNK] කළ හැකිද [end]\n",
            "-\n",
            "I can't come now.\n",
            "[start] මට දැන් යන්න බෑ [end]\n",
            "-\n",
            "Our marriage is over.\n",
            "[start] අපේ රැස්වීමට [UNK] [end]\n",
            "-\n",
            "What kind of bird is this?\n",
            "[start] එය කුමන ආකාරයේ [UNK] [end]\n",
            "-\n",
            "Why do American parents praise their children?\n",
            "[start] දරුවන් [UNK] [UNK] [UNK] ඇයි [end]\n",
            "-\n",
            "How about stopping the car and taking a rest?\n",
            "[start] අපි නිදා ගැනීමට යන මෝටර් රථය ගැන මොකද දෙන්නේ [end]\n",
            "-\n",
            "Tom can't sleep without his teddy bear.\n",
            "[start] ටොම් ඔහුගේ වයස [UNK] අනුව නිදා ගත නොහැක [end]\n",
            "-\n",
            "Tom held up his right hand.\n",
            "[start] ටොම් වහාම අත දිගු කළේය [end]\n",
            "-\n",
            "I have a slight pain in my side.\n",
            "[start] මගේ පැත්තේ මම පොඩි වේදනාව පහත් කළා [end]\n",
            "-\n",
            "Tom found a gun near the garbage can.\n",
            "[start] ටොම්ට කහ ස්ෙවටර් එකක් පෙන්වන්නම් [end]\n",
            "-\n",
            "We don't need any more volunteers, but we could use some more money.\n",
            "[start] අපට තවත් හොඳ අවස්ථාව අවශ්‍ය නොවේ නමුත් ඔහුට තවත් කාලය ගත හැකිය [end]\n",
            "-\n",
            "Believe it or not, this woman has three kids.\n",
            "[start] විශ්වාස කරන්න හෝ දරුවන් මේ මහලු කෙනෙක් ඒක නැහැ [end]\n",
            "-\n",
            "All the English teachers at my son's school are native speakers.\n",
            "[start] මගේ දරුවන්ට පහුගිය පාසලට වඩා නියම මිනිස්සු පන්ති එපා වෙලා [end]\n"
          ]
        }
      ]
    }
  ]
}